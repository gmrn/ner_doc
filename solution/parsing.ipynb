{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "### **Парсер: подготовка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv \n",
    "from data.labels import labels\n",
    "\n",
    "\n",
    "path = 'data/'\n",
    "label1 = labels['label1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_csv(path + 'train.csv', index_col='id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = read_csv(path + 'target.csv', index_col='id')\n",
    "tar.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#### **nerpa extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nerpa\n",
    "from rules.rules import(\n",
    "    Contract, Guarantee,\n",
    "    Amount,\n",
    "    Addition\n",
    ")\n",
    "\n",
    "exone = nerpa.Extractor(\n",
    "    [Contract, Amount, Addition])\n",
    "extwo = nerpa.Extractor(\n",
    "    [Guarantee, Amount, Addition])\n",
    "\n",
    "def switch_extractor(label):\n",
    "    return exone if label == label1 else extwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, _ in train.iloc[61:64].iterrows():\n",
    "\n",
    "    lb = _['label']\n",
    "    txt = _['text']\n",
    "\n",
    "    ex_ = switch_extractor(lb)\n",
    "             \n",
    "    nerpack = nerpa.NERpack(entities=ex_(txt))\n",
    "    \n",
    "    nerpack.show(txt)\n",
    "    print(nerpack.entities) \n",
    "\n",
    "    print(nerpack.markstr() + '\\n')    #   show mark's tags "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#### **false negative/positive errors**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим пустые записи в `extracted_part`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = tar['stop'] - tar['start']\n",
    "\n",
    "answ_on = tar[len != 0].index\n",
    "answ_off = tar[len == 0].index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем ошибки 1 и 2 рода, где парсер нашел пункт, хотя ответа нет и где не нашел, но ответ есть\n",
    "\n",
    "В идеале оба массива ошибок должны быть пустыми, но в приоритете избавиться от ошибок типа *false negative* (II), так как мы сразу отбросим эти записи и больше не сможем с ними работать\n",
    "\n",
    "Ошибки типа *false positive* (I) могут отсеяться на следующих этапах парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_check = nerpa.Extractor([Contract])\n",
    "two_check = nerpa.Extractor([Guarantee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_off = []  # search all labeloff docs\n",
    "\n",
    "for id, _ in train.iterrows():\n",
    "\n",
    "    lb =  _['label']\n",
    "    txt = _['text']\n",
    "\n",
    "    extractor = (one_check \n",
    "                 if lb == label1 \n",
    "                 else two_check)\n",
    "\n",
    "    if extractor.empty(txt):\n",
    "        label_off.append(id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_on = [x for x in train.index \n",
    "            if x not in label_off]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsI = [x for x in label_on if x in answ_off]\n",
    "errorsII = [x for x in label_off if x in answ_on]\n",
    "\n",
    "print(errorsI, errorsII)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корректируем правила для [labels](rules/entities/label.py)\n",
    "\n",
    "```python\n",
    "CONTRACT = rule(\n",
    "    or_(\n",
    "        normalized('обеспечение'),\n",
    "        normalized('исполнение'),\n",
    "    ).repeatable(),\n",
    "    normalized('настоящий').optional(),\n",
    "    or_(\n",
    "        normalized('контракт'),\n",
    "        normalized('договор'),\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      >>>execute 4th, 5th code cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем из датасета записи, где парсер не нашел нужный лэйбл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[label_on]\n",
    "train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#### **nerpa extractor**\n",
    "\n",
    "`Extractor nerpa` сделан на [yargy](https://github.com/natasha/yargy), подсветка реализована с помощью [ipymarkup](https://github.com/natasha/ipymarkup).\n",
    "Все инструменты из open source проекта `natasha`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_check = nerpa.Extractor([Amount])\n",
    "amount_off = []\n",
    "\n",
    "for id, _ in train.iterrows():\n",
    "    txt = _['text']     \n",
    "    if amount_check.empty(txt):\n",
    "        amount_off.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_off == errorsI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train.drop(train.loc[amount_off].index)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_entries(markstr, patterns):\n",
    "    entries = []\n",
    "    for __ in patterns:\n",
    "        entries += [_.start() for _ in re.finditer(__, markstr)]\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addonep = ['312', '132']    #   ['ADD{1,2}₽', '{1,2}ADD₽']\n",
    "onep = ['12']   #   '{1,2}₽'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_entries = []\n",
    "\n",
    "for id, _ in train.iterrows():\n",
    "\n",
    "    lb = _['label']\n",
    "    txt = _['text']\n",
    "             \n",
    "    extractor = switch_extractor(lb)\n",
    "    nerpack = nerpa.NERpack()\n",
    "    nerpack.add_marks(extractor(txt))\n",
    "    \n",
    "    markstr = (nerpack.markstr()\n",
    "                    .replace('2', '1')\n",
    "                    .replace('₽', '2') \n",
    "                    .replace('ADD', '3')\n",
    "                    )\n",
    "    pattern_entry = find_entries(markstr, addonep)\n",
    "\n",
    "    pattern_entries.append(\n",
    "        pattern_entry if pattern_entry \n",
    "        else find_entries(markstr, onep)\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import length_hint\n",
    "length_hint(pattern_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, _ in train.iterrows():\n",
    "\n",
    "#     lb = _['label']\n",
    "#     txt = _['text']\n",
    "\n",
    "#     extractor = switch_extractor(lb)\n",
    "             \n",
    "#     nerpack = nerpa.NERpack()\n",
    "#     nerpack.add_marks(extractor(txt))\n",
    "    \n",
    "#     nerpack.show(txt)\n",
    "#     print(nerpack.entities) \n",
    "\n",
    "#     print(nerpack.markstr() + '\\n')    #   show mark's tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from natasha import (\n",
    "#     Segmenter,\n",
    "#     MorphVocab,\n",
    "\n",
    "#     NewsEmbedding,\n",
    "#     NewsMorphTagger,\n",
    "#     NewsSyntaxParser,\n",
    "#     MoneyExtractor,\n",
    "#     Doc\n",
    "\n",
    "# )\n",
    "\n",
    "# from razdel import tokenize\n",
    "# from razdel import sentenize\n",
    "\n",
    "# tokens = list(tokenize(train[0]['text']))\n",
    "# for _ in tokens:\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "# segmenter = Segmenter()\n",
    "# morph_vocab = MorphVocab()\n",
    "\n",
    "# emb = NewsEmbedding()\n",
    "# morph_tagger = NewsMorphTagger(emb)\n",
    "# syntax_parser = NewsSyntaxParser(emb)\n",
    "\n",
    "\n",
    "# text = text[spans[0].start:spans[-1].stop]\n",
    "# text = 'Способ обеспечения исполнения контракта, гарантийных обязательств'\n",
    "# doc = Doc(text)\n",
    "\n",
    "# doc.segment(segmenter)\n",
    "# doc.tag_morph(morph_tagger)\n",
    "# doc.parse_syntax(syntax_parser)\n",
    "\n",
    "# sent = doc.sents[0]\n",
    "# # sent.morph.print()\n",
    "\n",
    "\n",
    "# sent.syntax.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
